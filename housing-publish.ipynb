{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n![Ames Housing dataset image](https://i.imgur.com/lTJVG4e.png)\n\nThis notebook is Fork of Exercise: Pipelines from [Intermediate Machine Learning Home Page](https://www.kaggle.com/learn/intermediate-machine-learning)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/test.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/data_description.txt\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import my own script\nimport utility as util\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"help(util)","execution_count":5,"outputs":[{"output_type":"stream","text":"Help on module utility:\n\nNAME\n    utility\n\nDESCRIPTION\n    # %% [code]\n    ## utility.py\n    ## This code is made by Tomo Shimobayashi.\n    ## Usage of Functions:\n    ## \n    ## - load_data(path, filename)\n    ##   import cvs to dataframe \n    ##   Returns pd.Dataframe\n    ##\n    ## - check_df(df)\n    ##   checking the numbers of NaNs and Duplicates in the data frame\n    ##\n    ## - num_cat_colname(X)\n    ##   Returns two arrays: num_array, cat_array as an array\n    ##       numerical value array and categorical value array\n    ##   input: X should be a Dafaframe\n    ##   \n    ## - regres_models(X_train, y_train)\n    ##   Try some regression models: Random Forest and Gradient Boosting\n    ##   The scoring method is neg_mean_abs_error\n    ##\n\nFUNCTIONS\n    check_df(df)\n    \n    load_data(path, filename)\n    \n    num_cat_colname(X)\n    \n    regres_models(X_train, y_train)\n\nFILE\n    /kaggle/usr/lib/utility/utility.py\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the data\npath = '/kaggle/input/home-data-for-ml-course/'\nX_full = util.load_data(path, 'train.csv')\nX_test_full = util.load_data(path, 'test.csv')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n# categorical_cols = [cname for cname in X_train_full.columns if\n#                     X_train_full[cname].nunique() < 10 and \n#                     X_train_full[cname].dtype == \"object\"]\n\n# # Select numerical columns\n# numerical_cols = [cname for cname in X_train_full.columns if \n#                 X_train_full[cname].dtype in ['int64', 'float64']]\n\nnumerical_cols, categorical_cols = util.num_cat_colname(X_train_full)\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"    MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope  \\\n618       RL   Pave   NaN      Reg         Lvl    AllPub    Inside       Gtl   \n870       RL   Pave   NaN      Reg         Lvl    AllPub    Inside       Gtl   \n92        RL   Pave  Grvl      IR1         HLS    AllPub    Inside       Gtl   \n817       RL   Pave   NaN      IR1         Lvl    AllPub   CulDSac       Gtl   \n302       RL   Pave   NaN      IR1         Lvl    AllPub    Corner       Gtl   \n\n    Condition1 Condition2  ... GarageArea WoodDeckSF OpenPorchSF  \\\n618       Norm       Norm  ...        774          0         108   \n870       PosN       Norm  ...        308          0           0   \n92        Norm       Norm  ...        432          0           0   \n817       Norm       Norm  ...        857        150          59   \n302       Norm       Norm  ...        843        468          81   \n\n    EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold  \n618             0         0         260        0       0      7   2007  \n870             0         0           0        0       0      8   2009  \n92             44         0           0        0       0      8   2009  \n817             0         0           0        0       0      7   2008  \n302             0         0           0        0       0      1   2006  \n\n[5 rows x 77 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSZoning</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>LandSlope</th>\n      <th>Condition1</th>\n      <th>Condition2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>618</th>\n      <td>RL</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>...</td>\n      <td>774</td>\n      <td>0</td>\n      <td>108</td>\n      <td>0</td>\n      <td>0</td>\n      <td>260</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>870</th>\n      <td>RL</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>PosN</td>\n      <td>Norm</td>\n      <td>...</td>\n      <td>308</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>RL</td>\n      <td>Pave</td>\n      <td>Grvl</td>\n      <td>IR1</td>\n      <td>HLS</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>...</td>\n      <td>432</td>\n      <td>0</td>\n      <td>0</td>\n      <td>44</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>817</th>\n      <td>RL</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>CulDSac</td>\n      <td>Gtl</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>...</td>\n      <td>857</td>\n      <td>150</td>\n      <td>59</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>RL</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>Gtl</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>...</td>\n      <td>843</td>\n      <td>468</td>\n      <td>81</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2006</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 77 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The next code cell uses code from the tutorial to preprocess the data and train a model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)\n                     ])\n\n# Preprocessing of training data, fit model \nclf.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = clf.predict(X_valid)\n\nprint('MAE:', mean_absolute_error(y_valid, preds))","execution_count":9,"outputs":[{"output_type":"stream","text":"MAE: 17740.290308219177\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The code yields a value around 17862 for the mean absolute error (MAE).  In the next step, I amend the code to do better.\n\n# Step 1: Improve the performance\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='mean') \n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Define model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0) ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(X_valid)\n\n# Evaluate the model\nscore = mean_absolute_error(y_valid, preds)\nprint('MAE:', score)\n","execution_count":11,"outputs":[{"output_type":"stream","text":"MAE: 17721.08506849315\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_p = preprocessor.fit_transform(X_train)\nX_valid_p = preprocessor.transform(X_valid)\nX_test_p = preprocessor.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"util.regres_models(X_train_p, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Generate test predictions\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor(random_state=0)\ngbr.fit(X_train_p, y_train)\npreds_test = gbr.predict(X_test_p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test['Id'],\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import eli5\n# from eli5.sklearn import PermutationImportance\n# X_train_p = preprocessor.transform(X_train)\n# imputer = SimpleImputer(strategy='most_frequent')\n# X_train_imp = imputer.fit_transform(X_train[categorical_cols])\n# onehot = OneHotEncoder(handle_unknown='ignore')\n# onehot.fit(X_train_imp)\n\n# perm = PermutationImportance(model, random_state=1).fit(X_train_p, y_train)\n# column_array = X_train[numerical_cols].columns.tolist()\n# column_array.extend(onehot.get_feature_names(X_train[categorical_cols].columns.tolist()))\n# eli5.show_weights(perm, feature_names = column_array)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}